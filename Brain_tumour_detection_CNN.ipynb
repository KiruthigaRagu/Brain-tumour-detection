{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Brain_tumour_detection_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaY90UES8eov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvEkqF4Niglj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Unit(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super(Unit,self).__init__()\n",
        "        \n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,kernel_size=3,out_channels=out_channels,stride=1,padding=1)\n",
        "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,input):\n",
        "        output = self.conv(input)\n",
        "        output = self.bn(output)\n",
        "        output = self.relu(output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9WqoFqUikgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self,num_classes=2):\n",
        "        super(SimpleNet,self).__init__()\n",
        "\n",
        "        #Create 14 layers of the unit with max pooling in between\n",
        "        self.unit1 = Unit(in_channels=3,out_channels=32)\n",
        "        self.unit2 = Unit(in_channels=32, out_channels=32)\n",
        "        self.unit3 = Unit(in_channels=32, out_channels=32)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit4 = Unit(in_channels=32, out_channels=64)\n",
        "        self.unit5 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit6 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit7 = Unit(in_channels=64, out_channels=64)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit8 = Unit(in_channels=64, out_channels=128)\n",
        "        self.unit9 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit10 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit11 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit12 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit13 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit14 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
        "        \n",
        "        #Add all the units into the Sequential layer in exact order\n",
        "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, self.unit4, self.unit5, self.unit6\n",
        "                                 ,self.unit7, self.pool2, self.unit8, self.unit9, self.unit10, self.unit11, self.pool3,\n",
        "                                 self.unit12, self.unit13, self.unit14, self.avgpool)\n",
        "\n",
        "        self.fc = nn.Linear(in_features=128,out_features=num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.net(input)\n",
        "        output = output.view(-1,128)\n",
        "        output = self.fc(output)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERHhvKxdl3pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transformations = transforms.Compose([                                        \n",
        "    transforms.Resize((32,32),interpolation=2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "batch_size = 32\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjQofheZjdbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_transformations = transforms.Compose([\n",
        "    transforms.Resize((32,32),interpolation=2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNa312AHiwUx",
        "colab_type": "code",
        "outputId": "703017dd-d964-449b-f390-ea33f9f96aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USCjbMfMhGEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG4SMUSLNwz_",
        "colab_type": "code",
        "outputId": "5a948731-46a9-41da-d0ee-49cea2b0a48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNIXmXvCi5_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in each dataset and apply transformations using\n",
        "# the torchvision.datasets as datasets library\n",
        "train_set = datasets.ImageFolder(\"Brain_tumor_detection/Train/\", transform = train_transformations)\n",
        "test_set = datasets.ImageFolder(\"Brain_tumor_detection/Test\", transform = test_transformations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXr17cRijETi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,batch_size=batch_size,shuffle=False,num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOkMeGq6jtu3",
        "colab_type": "code",
        "outputId": "32baeb6f-84f6-4146-bd5f-f6b987bf429c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Check if gpu support is available\n",
        "cuda_avail = torch.cuda.is_available()\n",
        "\n",
        "#Create model, optimizer and loss function\n",
        "model = SimpleNet(num_classes=2)\n",
        "\n",
        "if cuda_avail:\n",
        "    model.cuda()\n",
        "    print(cuda_avail)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWBTuNIWkEnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(model.parameters(), lr=0.001,weight_decay=0.0001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq1YTsegkHit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a learning rate adjustment function that divides the learning rate by 10 every 30 epochs\n",
        "def adjust_learning_rate(epoch):\n",
        "\n",
        "    lr = 0.001\n",
        "\n",
        "    if epoch > 180:\n",
        "        lr = lr / 1000000\n",
        "    elif epoch > 150:\n",
        "        lr = lr / 100000\n",
        "    elif epoch > 120:\n",
        "        lr = lr / 10000\n",
        "    elif epoch > 90:\n",
        "        lr = lr / 1000\n",
        "    elif epoch > 60:\n",
        "        lr = lr / 100\n",
        "    elif epoch > 30:\n",
        "        lr = lr / 10\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RNFseSCkKzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_models(epoch):\n",
        "    torch.save(model.state_dict(), \"Classifier_{}.model\".format(epoch))\n",
        "    print(\"Checkpoint saved\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh5Hq9JfkSK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_acc = 0.0\n",
        "    for i, (images, labels) in enumerate(test_loader):\n",
        "      \n",
        "        if cuda_avail:\n",
        "                images = Variable(images.cuda())\n",
        "                labels = Variable(labels.cuda())\n",
        "\n",
        "        #Predict classes using images from the test set\n",
        "        outputs = model(images)\n",
        "        _,prediction = torch.max(outputs.data, 1)\n",
        "        prediction = prediction.cpu().numpy()\n",
        "        for i in range(len(images)):\n",
        "              if prediction[i] == labels.data[i]:\n",
        "                test_acc +=1\n",
        "        \n",
        "\n",
        "\n",
        "    #Compute the average acc and loss over all 10000 test images\n",
        "    test_acc = test_acc / 73\n",
        "\n",
        "    return test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXTpj7w-kXVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(num_epochs):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_acc = 0.0\n",
        "        train_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            #Move images and labels to gpu if available\n",
        "            if cuda_avail:\n",
        "                images = Variable(images.cuda())\n",
        "                labels = Variable(labels.cuda())\n",
        "\n",
        "            #Clear all accumulated gradients\n",
        "            optimizer.zero_grad()\n",
        "            #Predict classes using images from the test set\n",
        "            outputs = model(images)\n",
        "            #Compute the loss based on the predictions and actual labels\n",
        "            loss = loss_fn(outputs,labels)\n",
        "            #Backpropagate the loss\n",
        "            loss.backward()\n",
        "\n",
        "            #Adjust parameters according to the computed gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.cpu().data * images.size(0)\n",
        "            _, prediction = torch.max(outputs.data, 1)\n",
        "            \n",
        "            #train_acc += torch.sum(prediction == labels.data)\n",
        "            for i in range(len(images)):\n",
        "              if prediction[i] == labels.data[i]:\n",
        "                train_acc +=1\n",
        "\n",
        "        #Call the learning rate adjustment function\n",
        "        adjust_learning_rate(epoch)\n",
        "\n",
        "        #Compute the average acc and loss over all 50000 training images\n",
        "        train_acc = train_acc / 180\n",
        "        train_loss = train_loss / 180\n",
        "\n",
        "        #Evaluate on the test set\n",
        "        test_acc = test()\n",
        "\n",
        "        # Save the model if the test acc is greater than our current best\n",
        "        if test_acc > best_acc:\n",
        "            save_models(epoch)\n",
        "            best_acc = test_acc\n",
        "\n",
        "\n",
        "        # Print the metrics\n",
        "        print(\"Epoch {}, Train Accuracy: {} , TrainLoss: {} , Test Accuracy: {}\".format(epoch, train_acc, train_loss,test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbPYd7rBkejH",
        "colab_type": "code",
        "outputId": "68038894-69e6-4fbc-de87-c659da0f4565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoint saved\n",
            "Epoch 0, Train Accuracy: 0.9611111111111111 , TrainLoss: 0.12700968980789185 , Test Accuracy: 0.8082191780821918\n",
            "Epoch 1, Train Accuracy: 0.9555555555555556 , TrainLoss: 0.12232720851898193 , Test Accuracy: 0.7397260273972602\n",
            "Epoch 2, Train Accuracy: 0.9611111111111111 , TrainLoss: 0.10010389983654022 , Test Accuracy: 0.7808219178082192\n",
            "Epoch 3, Train Accuracy: 0.9944444444444445 , TrainLoss: 0.05497673898935318 , Test Accuracy: 0.7397260273972602\n",
            "Epoch 4, Train Accuracy: 0.9888888888888889 , TrainLoss: 0.060679659247398376 , Test Accuracy: 0.6575342465753424\n",
            "Epoch 5, Train Accuracy: 0.9833333333333333 , TrainLoss: 0.07743126899003983 , Test Accuracy: 0.7534246575342466\n",
            "Epoch 6, Train Accuracy: 0.9833333333333333 , TrainLoss: 0.04477892816066742 , Test Accuracy: 0.6986301369863014\n",
            "Epoch 7, Train Accuracy: 0.95 , TrainLoss: 0.14421346783638 , Test Accuracy: 0.5342465753424658\n",
            "Epoch 8, Train Accuracy: 0.9555555555555556 , TrainLoss: 0.1134314015507698 , Test Accuracy: 0.6575342465753424\n",
            "Checkpoint saved\n",
            "Epoch 9, Train Accuracy: 0.9666666666666667 , TrainLoss: 0.10470101982355118 , Test Accuracy: 0.821917808219178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9aya5sXkxoV",
        "colab_type": "code",
        "outputId": "45632833-7d58-4195-9b0e-2e487cc30c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#for inputs, labels in test_loader:\n",
        " # print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8O4VwFAIHsk",
        "colab_type": "code",
        "outputId": "53fdd048-fc86-4fb8-cdcb-bb49871812fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#test_loader.dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 73\n",
              "    Root location: Brain_tumor_detection/Test\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=(32, 32), interpolation=PIL.Image.BILINEAR)\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "           )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVYq5K6eJfTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}